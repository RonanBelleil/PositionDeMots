{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusions des embbeddings pour CamemBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain, combinations\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.model_selection\n",
    "from sklearn import svm\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions utilitaires (combinaisons, convsion liste/dictionnaire...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforme une liste de fichiers en dictionnaire de fichiers avec les même proportion d'embbeddings\n",
    "def listToDicSameProp(lst):\n",
    "    return {elt: 1./len(lst) for elt in lst}\n",
    "\n",
    "# Créer toute les combinaisons\n",
    "def listToDicCombiSameProp(lst, minLen=1, maxLen=-1):\n",
    "    if maxLen == -1:\n",
    "        maxLen = len(lst)\n",
    "    return [listToDicSameProp(x) for x in chain.from_iterable(combinations(lst, r) for r in range(minLen, maxLen+1))]\n",
    "\n",
    "# Fusion de listes\n",
    "def listMerge2(lst1, lst2, prop1):\n",
    "    return [{elt1: prop1, elt2: 1.-prop1} for elt1 in lst1 for elt2 in lst2]\n",
    "\n",
    "# Effectu un dégradé sur le coefficient entre deux embbeddings\n",
    "def eltsGradient(elt1, elt2):\n",
    "    return [{elt1: x, elt2: 1.-x} for x in np.arange(.1, 1., 0.1)]\n",
    "\n",
    "# Convertie une liste en dictionnaire avec les éléments de la\n",
    "# liste lst comme clé et une valeur unique val comme valeur\n",
    "def listToDic(lst, val):\n",
    "    return {elt: val for elt in lst}\n",
    "\n",
    "# Convertie plusieurs liste en plusieurs dictionnaires avec les éléments des\n",
    "# listes lsts[i] comme clé et une valeur unique val comme valeur\n",
    "def listsToDic(lsts, val):\n",
    "    return [listToDic(lst, val) for lst in lsts]\n",
    "\n",
    "# Renvoi une liste dans laquel chaque élément est une liste avec un élément de moins à chaque fois :\n",
    "# [1, 2, 3] devient [[1], [1, 2], [1, 2, 3]]\n",
    "def decrList(lst):\n",
    "    return [lst[0:i+1] for i in range(len(lst))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement d'un ensemble d'embbeddings, fusion et tests\n",
    "Cette fonction charge un ensemble d'embbeddings et fait le mélange entre ces embbeddings :\n",
    "- Soit avec une moyenne pondéré par les coeficients indiqué ($x_j = \\sum_{i=0}^n c_i x_{ij}$ avec $x_j$ l'embbedding de la phrase $j$ résultant, $n$ le nombre de fichiers, $c_i$ le coefficient du fichier $i$ et $x_ij$ l'embbedding de la phrase $j$ du fichier $i$).\n",
    "- Soit avec une concaténation des embbeddings (donc l'embbedding $x_j$ sera de dimension $\\sum_{i=0}^n dim(x_ij)$)\n",
    "\n",
    "Ensuite le SVM calcul le résultat sur ces nouveau embbeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testEmbd(filenames, concat=False):\n",
    "    # Chargement des données\n",
    "    X = np.ndarray((0,0))\n",
    "    y = []\n",
    "    for embdFile, proportion in filenames.items():\n",
    "        dataFile = np.load(embdFile, allow_pickle=True)\n",
    "        if concat:\n",
    "            proportion = 1.\n",
    "        if len(X) == 0:\n",
    "            X = proportion*dataFile\n",
    "        else:\n",
    "            if concat:\n",
    "                X = np.concatenate((X, proportion*dataFile), axis=1)\n",
    "            else:\n",
    "                X += proportion*dataFile\n",
    "    y = np.load(\"label.npy\")\n",
    "\n",
    "    # Tests\n",
    "    cv = sklearn.model_selection.ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "    clf = svm.SVC(kernel='rbf', C=1, random_state=42)\n",
    "    results = cross_val_score(clf, X, y, cv=cv, scoring=\"f1\")\n",
    "    print(\"F-score de la validation croisée : \", results)\n",
    "    print(\"Moyenne des F-score\", np.mean(results))\n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de tests de différentes combinaisons d'embbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchTestEmbd(filenamesLists, concat=False):\n",
    "    print(len(filenamesLists))\n",
    "    return {str(filenames): testEmbd(filenames, concat) for filenames in filenamesLists}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'POS5.npy': 1.0},\n",
       " {'POS5.npy': 1.0, 'LRInv1.npy': 1.0},\n",
       " {'POS5.npy': 1.0, 'LRInv1.npy': 1.0, 'POS3.npy': 1.0},\n",
       " {'POS5.npy': 1.0, 'LRInv1.npy': 1.0, 'POS3.npy': 1.0, 'POS4.npy': 1.0},\n",
       " {'POS5.npy': 1.0,\n",
       "  'LRInv1.npy': 1.0,\n",
       "  'POS3.npy': 1.0,\n",
       "  'POS4.npy': 1.0,\n",
       "  'POS1.npy': 1.0},\n",
       " {'POS5.npy': 1.0,\n",
       "  'LRInv1.npy': 1.0,\n",
       "  'POS3.npy': 1.0,\n",
       "  'POS4.npy': 1.0,\n",
       "  'POS1.npy': 1.0,\n",
       "  'POS2.npy': 1.0},\n",
       " {'POS5.npy': 1.0,\n",
       "  'LRInv1.npy': 1.0,\n",
       "  'POS3.npy': 1.0,\n",
       "  'POS4.npy': 1.0,\n",
       "  'POS1.npy': 1.0,\n",
       "  'POS2.npy': 1.0,\n",
       "  'alea3.npy': 1.0},\n",
       " {'POS5.npy': 1.0,\n",
       "  'LRInv1.npy': 1.0,\n",
       "  'POS3.npy': 1.0,\n",
       "  'POS4.npy': 1.0,\n",
       "  'POS1.npy': 1.0,\n",
       "  'POS2.npy': 1.0,\n",
       "  'alea3.npy': 1.0,\n",
       "  'LRInv3.npy': 1.0},\n",
       " {'POS5.npy': 1.0,\n",
       "  'LRInv1.npy': 1.0,\n",
       "  'POS3.npy': 1.0,\n",
       "  'POS4.npy': 1.0,\n",
       "  'POS1.npy': 1.0,\n",
       "  'POS2.npy': 1.0,\n",
       "  'alea3.npy': 1.0,\n",
       "  'LRInv3.npy': 1.0,\n",
       "  'LRInv2.npy': 1.0},\n",
       " {'POS5.npy': 1.0,\n",
       "  'LRInv1.npy': 1.0,\n",
       "  'POS3.npy': 1.0,\n",
       "  'POS4.npy': 1.0,\n",
       "  'POS1.npy': 1.0,\n",
       "  'POS2.npy': 1.0,\n",
       "  'alea3.npy': 1.0,\n",
       "  'LRInv3.npy': 1.0,\n",
       "  'LRInv2.npy': 1.0,\n",
       "  'LRInvTotal.npy': 1.0},\n",
       " {'POS5.npy': 1.0,\n",
       "  'LRInv1.npy': 1.0,\n",
       "  'POS3.npy': 1.0,\n",
       "  'POS4.npy': 1.0,\n",
       "  'POS1.npy': 1.0,\n",
       "  'POS2.npy': 1.0,\n",
       "  'alea3.npy': 1.0,\n",
       "  'LRInv3.npy': 1.0,\n",
       "  'LRInv2.npy': 1.0,\n",
       "  'LRInvTotal.npy': 1.0,\n",
       "  'alea1.npy': 1.0},\n",
       " {'POS5.npy': 1.0,\n",
       "  'LRInv1.npy': 1.0,\n",
       "  'POS3.npy': 1.0,\n",
       "  'POS4.npy': 1.0,\n",
       "  'POS1.npy': 1.0,\n",
       "  'POS2.npy': 1.0,\n",
       "  'alea3.npy': 1.0,\n",
       "  'LRInv3.npy': 1.0,\n",
       "  'LRInv2.npy': 1.0,\n",
       "  'LRInvTotal.npy': 1.0,\n",
       "  'alea1.npy': 1.0,\n",
       "  'alea4.npy': 1.0},\n",
       " {'POS5.npy': 1.0,\n",
       "  'LRInv1.npy': 1.0,\n",
       "  'POS3.npy': 1.0,\n",
       "  'POS4.npy': 1.0,\n",
       "  'POS1.npy': 1.0,\n",
       "  'POS2.npy': 1.0,\n",
       "  'alea3.npy': 1.0,\n",
       "  'LRInv3.npy': 1.0,\n",
       "  'LRInv2.npy': 1.0,\n",
       "  'LRInvTotal.npy': 1.0,\n",
       "  'alea1.npy': 1.0,\n",
       "  'alea4.npy': 1.0,\n",
       "  'alea5.npy': 1.0},\n",
       " {'POS5.npy': 1.0,\n",
       "  'LRInv1.npy': 1.0,\n",
       "  'POS3.npy': 1.0,\n",
       "  'POS4.npy': 1.0,\n",
       "  'POS1.npy': 1.0,\n",
       "  'POS2.npy': 1.0,\n",
       "  'alea3.npy': 1.0,\n",
       "  'LRInv3.npy': 1.0,\n",
       "  'LRInv2.npy': 1.0,\n",
       "  'LRInvTotal.npy': 1.0,\n",
       "  'alea1.npy': 1.0,\n",
       "  'alea4.npy': 1.0,\n",
       "  'alea5.npy': 1.0,\n",
       "  'alea2.npy': 1.0},\n",
       " {'POS5.npy': 1.0,\n",
       "  'LRInv1.npy': 1.0,\n",
       "  'POS3.npy': 1.0,\n",
       "  'POS4.npy': 1.0,\n",
       "  'POS1.npy': 1.0,\n",
       "  'POS2.npy': 1.0,\n",
       "  'alea3.npy': 1.0,\n",
       "  'LRInv3.npy': 1.0,\n",
       "  'LRInv2.npy': 1.0,\n",
       "  'LRInvTotal.npy': 1.0,\n",
       "  'alea1.npy': 1.0,\n",
       "  'alea4.npy': 1.0,\n",
       "  'alea5.npy': 1.0,\n",
       "  'alea2.npy': 1.0,\n",
       "  'messages_equilibre_ok.npy': 1.0}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liste des tests a effectuer\n",
    "# Pour chaque test : un dictionnaire fichier embbedding -> ratio de ce fichier\n",
    "filenamesLists = listsToDic(decrList([\"POS5.npy\", \"LRInv1.npy\", \"POS3.npy\", \"POS4.npy\", \"POS1.npy\", \"POS2.npy\", \"alea3.npy\", \"LRInv3.npy\", \"LRInv2.npy\", \"LRInvTotal.npy\", \"alea1.npy\", \"alea4.npy\", \"alea5.npy\", \"alea2.npy\", \"messages_equilibre_ok.npy\"]), 1.)\n",
    "batchTestEmbd(filenamesLists, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
